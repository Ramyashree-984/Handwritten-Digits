{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd291db",
   "metadata": {},
   "source": [
    "# Handwritten Digits Image Processing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aefab1",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfff4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_data(path):\n",
    "    with np.load(path) as f:\n",
    "        x_train, y_train = f['x_train'], f['y_train']\n",
    "        x_test, y_test = f['x_test'], f['y_test']\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data('mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca1921d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c3f51",
   "metadata": {},
   "source": [
    "Insights:\n",
    "- The dataset contains 60,000 small square 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6719eeb2",
   "metadata": {},
   "source": [
    "## Business Case:\n",
    "- The task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0b16f",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8cee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fb917",
   "metadata": {},
   "source": [
    "## Scaling input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735f71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling input data\n",
    "# Input data is vary from 0(Black) to 255(White). so here scaling in between 0 to 1\n",
    "num_of_trainImgs = x_train.shape[0] #60000 here\n",
    "num_of_testImgs = x_test.shape[0] #10000 here\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_height, img_width, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_height, img_width, 1)\n",
    "input_shape = (img_height, img_width, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9d824",
   "metadata": {},
   "source": [
    "## Conversion of class vectors into binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d012258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion of class vectors into binary values\n",
    "num_classes = 10\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0327c8db",
   "metadata": {},
   "source": [
    "## Defining model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model architecture\n",
    "\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae163c3d",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fad9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "#Compiling the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14532a32",
   "metadata": {},
   "source": [
    "## Fitting model to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3305e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1714/1714 [==============================] - 166s 94ms/step - loss: 0.1838 - accuracy: 0.9445\n",
      "Epoch 2/12\n",
      "1714/1714 [==============================] - 164s 96ms/step - loss: 0.0771 - accuracy: 0.9773\n",
      "Epoch 3/12\n",
      "1714/1714 [==============================] - 160s 93ms/step - loss: 0.0594 - accuracy: 0.9821\n",
      "Epoch 4/12\n",
      "1714/1714 [==============================] - 160s 93ms/step - loss: 0.0481 - accuracy: 0.9851\n",
      "Epoch 5/12\n",
      "1714/1714 [==============================] - 160s 93ms/step - loss: 0.0413 - accuracy: 0.9866\n",
      "Epoch 6/12\n",
      "1714/1714 [==============================] - 162s 95ms/step - loss: 0.0357 - accuracy: 0.9889\n",
      "Epoch 7/12\n",
      "1714/1714 [==============================] - 161s 94ms/step - loss: 0.0302 - accuracy: 0.9904\n",
      "Epoch 8/12\n",
      "1714/1714 [==============================] - 162s 94ms/step - loss: 0.0293 - accuracy: 0.9905\n",
      "Epoch 9/12\n",
      "1714/1714 [==============================] - 162s 94ms/step - loss: 0.0254 - accuracy: 0.9918\n",
      "Epoch 10/12\n",
      "1714/1714 [==============================] - 163s 95ms/step - loss: 0.0221 - accuracy: 0.9929\n",
      "Epoch 11/12\n",
      "1714/1714 [==============================] - 164s 96ms/step - loss: 0.0209 - accuracy: 0.9931\n",
      "Epoch 12/12\n",
      "1150/1714 [===================>..........] - ETA: 55s - loss: 0.0211 - accuracy: 0.9933WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 20568 batches). You may need to use the repeat() function when building your dataset.\n",
      "1714/1714 [==============================] - 121s 70ms/step - loss: 0.0211 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1861ee5c760>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting model to training data\n",
    "model.fit(x_train, y_train, epochs=12,steps_per_epoch = 1714)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2071dc",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce4548f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.030465831980109215\n",
      "Test accuracy: 0.9926000237464905\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0714abe",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41202d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model saving\n",
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86703aa",
   "metadata": {},
   "source": [
    "## Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0952bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, Image\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "\n",
    "        self.x = self.y = 0\n",
    "\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command = self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c91bf0",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee183db0",
   "metadata": {},
   "source": [
    "## CNN is having high accuracy and very effective in image recognition problem as compared to ANN and RNN.\n",
    "### Initially we got dataset from piece of code and then did data preprocessing.\n",
    "### Then followed CNN process and got best accurate value and less error for test.\n",
    "### To check model performance we created GUI using Tkinter and got best results\n",
    "\n",
    "## By above performance we conclude that CNN gives best performance to recognize HANDWRITTEN DIGITS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d7ec1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
